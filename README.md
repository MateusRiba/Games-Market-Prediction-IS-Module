# üéÆ Games Market Predictor

Previs√£o de **vendas globais e regionais** (NA, PAL, JP, Other) e **Metascore** para novos jogos a partir de atributos como plataforma, g√™neros, publisher, etc.

Inclui:

* **ETL** ‚Üí cria `data/processed/games.db` (SQLite).
* **Treino** ‚Üí treina 6 modelos (Random Forest) e salva em `ml/*.pkl`.
* **API** (**FastAPI**) ‚Üí endpoint de predi√ß√£o por alvo + endpoint de filtros.
* **App** (**Streamlit**) ‚Üí UI para an√°lise, previs√µes e simula√ß√£o de cen√°rios (pre√ßo e marketing).

---

## üìÅ Estrutura

```
.
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îî‚îÄ‚îÄ app/
‚îÇ       ‚îú‚îÄ‚îÄ main.py               # FastAPI (predict, filters)
‚îÇ       ‚îú‚îÄ‚îÄ models.py             # ORM (Game -> games_dim)
‚îÇ       ‚îî‚îÄ‚îÄ api/
‚îÇ           ‚îú‚îÄ‚îÄ filters.py
‚îÇ           ‚îî‚îÄ‚îÄ debug.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # CSVs de origem
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ       ‚îî‚îÄ‚îÄ games.db              # (gerado pelo ETL)
‚îú‚îÄ‚îÄ ml/
‚îÇ   ‚îú‚îÄ‚îÄ train_models.py           # treina e salva modelos
‚îÇ   ‚îî‚îÄ‚îÄ model_*.pkl               # (gerados localmente; ignorados no git)
‚îî‚îÄ‚îÄ streamlit_app/
    ‚îî‚îÄ‚îÄ app.py                    # frontend Streamlit
```
---

## Come√ßando

### 1) Pr√©-requisitos

* **Python 3.10 ‚Äì 3.12** (recomendado 3.11/3.12).
* Git instalado.

> **Importante (scikit-learn & pickles):** modelos salvos com uma vers√£o do `scikit-learn` podem dar erro se carregados com outra. Se ocorrer, **re-treine** os modelos (Se√ß√£o *Treinar modelos*).

---

### 2) Clonar e criar ambiente

```bash
git clone <URL-DO-REPO>
cd Games-Market-Prediction-IS-Module

# criar venv (Linux/macOS)
python -m venv .venv
source .venv/bin/activate

# ou no Windows PowerShell
python -m venv .venv
.\.venv\Scripts\Activate
```

---

### 3) Instalar depend√™ncias

Crie (ou apenas use) o arquivo `requirements.txt` com o conte√∫do abaixo e instale:

```bash
pip install -r requirements.txt
```

`requirements.txt` sugerido:

```txt
pandas>=2.2.2
numpy>=1.26.4
scikit-learn==1.5.2
joblib>=1.4.2

SQLAlchemy>=2.0.30
fastapi>=0.111.0
uvicorn[standard]>=0.30.0
pydantic>=2.7.0

streamlit>=1.33.0
plotly>=5.22.0

python-slugify>=8.0.4
rapidfuzz>=3.9.1
```

---

### 4) Preparar os dados (ETL) 

Coloque os CSVs originais em **`data/raw/`** com os nomes esperados (ajuste no script se necess√°rio):

* `games (1).csv` (Metacritic)
* `games_sales.csv` (VGChartz)

Execute:

```bash
python ETL_build_dataset.py
```

Sa√≠da esperada:
`ETL conclu√≠do ... linhas gravadas em data/processed/games.db`

OBS: ambos os datasets j√° est√£o disponiveis, ent√£o esse passo √© opcional.

---

### 5) Treinar modelos

```bash
python ml/train_models.py
```

Isso gera:

```
ml/model_sales_global.pkl
ml/model_sales_na.pkl
ml/model_sales_pal.pkl
ml/model_sales_jp.pkl
ml/model_sales_other.pkl
ml/model_metascore.pkl
```

Cada treino imprime o **MAE** de valida√ß√£o.

> Se aparecer erro de vers√£o do `scikit-learn` ao carregar pickles, **re-treine** com a vers√£o instalada (rodando o passo acima) ou alinhe a vers√£o do `scikit-learn` ao criar a venv.

---

### 6) Rodar o **backend** (FastAPI)

```bash
uvicorn backend.app.main:app --reload --port 8000
```

* **Docs interativas:** [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

Exemplos:

```bash
# Filtros (para popular selects do frontend)
curl http://127.0.0.1:8000/filters

# Predi√ß√£o de um alvo (ex.: vendas globais)
curl -X POST http://127.0.0.1:8000/predict/global_sales \
  -H "Content-Type: application/json" \
  -d '{"rating":"E","platform":["PS4"],"genres":["Action","Adventure"],
       "developer":"Ubisoft","publisher":"Ubisoft","year":2020}'
```

---

### 7) Rodar o **frontend** (Streamlit)

Em outro terminal (mesma venv):

```bash
python -m streamlit run streamlit_app/app.py --server.port 8501
```

* App local: [http://localhost:8501](http://localhost:8501)

No app voc√™ pode:

* Ver **Dashboard** com KPIs e gr√°ficos.
* Fazer **Previs√µes** e **simular cen√°rios**:

  * **Pre√ßo** (neutro = USD 60; fator baseado em **elasticidade pre√ßo‚Äìdemanda**).
  * **Marketing** (n√≠veis Baixo/M√©dio/Alto com impacto moderado).
* Ver **chance de sucesso** e **risco** a partir do **Metascore** previsto.
* Explorar dados hist√≥ricos e **insights**.

---

## Como funciona (resumo)

1. **ETL**: junta Metacritic + VGChartz via *slug* + *fuzzy matching*, normaliza colunas e grava em SQLite (`games_dim`).
2. **Treino**: `RandomForestRegressor` em *pipeline* com `OneHotEncoder(handle_unknown='ignore')`.
   Um modelo por alvo: `global_sales`, `na_sales`, `pal_sales`, `jp_sales`, `other_sales`, `metascore`.
3. **API**:

   * `POST /predict/{target}` ‚Üí recebe features (g√™neros at√© 2, plataforma, etc.), normaliza listas (concatena com `|`) e retorna a previs√£o do alvo.
   * `GET /filters` ‚Üí valores distintos de g√™nero, rating e plataforma (para o frontend).
4. **App**:

   * Carrega dados e modelos locais.
   * Aplica **fatores de cen√°rio** ap√≥s a previs√£o:

     * **Pre√ßo**: `factor = (price/60) ** (-Œµ)`, com `Œµ ‚âà 1.2` (limites de seguran√ßa).
     * **Marketing**: `Baixo=+5%`, `M√©dio=+25%`, `Alto=+50%` (efeito moderado com base em estudos de MMM/ind√∫stria).
   * **Chance de sucesso** e **risco**: fun√ß√£o monot√¥nica do Metascore previsto, exibida com barras de progresso.
   * Gr√°ficos: compara√ß√£o ‚Äúoriginal vs cen√°rio‚Äù e distribui√ß√£o regional.

---

## Dicas & Troubleshooting

* **Porta em uso**

  * Backend: `--port 8001`
  * Frontend: `--server.port 8502`

* **ModuleNotFoundError**

  * Garanta que a *venv* est√° ativa e rode `pip install -r requirements.txt`.

* **Erro ao carregar .pkl / `_RemainderColsList`**

  * Re-treine com `python ml/train_models.py`.

* **`games.db` n√£o encontrado**

  * Rode o **ETL** (Se√ß√£o 4).

* **Evitar commitar `.pkl`**

  * `.gitignore`:

    ```
    ml/*.pkl
    ml/*.joblib
    !ml/.gitkeep
    ```
  * Se j√° foram adicionados: `git rm --cached ml/*.pkl`

---

## üìö Bibliotecas (o que cada uma faz)
Caso o requirements n√£o funcione, √© tambem viavel baixar as bibliotecas individualmente.

* **pandas** ‚Äì manipula√ß√£o de dados tabulares (ETL, consultas, groupby).
* **numpy** ‚Äì opera√ß√µes num√©ricas/arrays.
* **scikit-learn** ‚Äì ML (pipelines, OneHotEncoder, RandomForestRegressor).
* **joblib** ‚Äì salvar/carregar modelos (`.pkl`).
* **SQLAlchemy** ‚Äì acesso ao **SQLite** (`data/processed/games.db`).
* **FastAPI** ‚Äì API REST (endpoints de predi√ß√£o e filtros).
* **uvicorn\[standard]** ‚Äì servidor ASGI para rodar a API.
* **pydantic** ‚Äì valida√ß√£o/serializa√ß√£o dos esquemas de entrada.
* **streamlit** ‚Äì frontend web para dashboards, explora√ß√£o e previs√µes.
* **plotly** ‚Äì gr√°ficos interativos no Streamlit.
* **python-slugify** ‚Äì gera slugs (IDs amig√°veis) para casar registros.
* **rapidfuzz** ‚Äì *fuzzy matching* veloz e preciso para unir fontes.

---

## ‚úÖ Roadmap curto (ideias)

* Cache de predi√ß√µes no backend.
* Valida√ß√£o de combina√ß√µes plataforma√óano.
* Feature store para reuso de encoders entre treino/produ√ß√£o.
* Testes unit√°rios para ETL e API (`pytest`) usando `tests/data/sample_games.csv`.

---

**Pronto!** Depois de seguir os passos (ETL ‚Üí Treino ‚Üí API ‚Üí App), voc√™ ter√° previs√µes e simula√ß√µes rodando localmente.
